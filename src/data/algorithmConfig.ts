export type AlgorithmType = 'PPO' | 'SAC' | 'TD3' | 'DDPG';

export type ParameterInputType = 'float' | 'int' | 'select';

export interface AlgorithmParameterDefinition {
  key: string;
  label: string;
  description: string;
  type: ParameterInputType;
  defaultValue: number | string;
  min?: number;
  max?: number;
  step?: number;
  options?: { label: string; value: string }[];
}

export interface AlgorithmTemplate {
  key: AlgorithmType;
  title: string;
  description: string;
  actionSpace: 'continuous';
  parameters: AlgorithmParameterDefinition[];
}

export type AlgorithmParameters = Record<string, number | string>;

export interface AlgorithmConfig {
  id: string;
  name: string;
  version: string;
  status: string;
  type: AlgorithmType;
  lastRun: string;
  throughput: string;
  parameters: AlgorithmParameters;
}

const ppoParameters: AlgorithmParameterDefinition[] = [
  {
    key: 'learningRate',
    label: 'Learning rate',
    description: 'Step size for Adam optimizer',
    type: 'float',
    defaultValue: 0.0003,
    min: 0.00001,
    max: 0.01,
    step: 0.00001,
  },
  {
    key: 'gamma',
    label: 'Discount factor (gamma)',
    description: 'Weighting of future rewards',
    type: 'float',
    defaultValue: 0.99,
    min: 0.8,
    max: 0.999,
    step: 0.001,
  },
  {
    key: 'gaeLambda',
    label: 'GAE lambda',
    description: 'Bias/variance trade-off for GAE',
    type: 'float',
    defaultValue: 0.95,
    min: 0.7,
    max: 1,
    step: 0.01,
  },
  {
    key: 'clipRange',
    label: 'Clip range',
    description: 'Trust region clipping',
    type: 'float',
    defaultValue: 0.2,
    min: 0.05,
    max: 0.4,
    step: 0.01,
  },
  {
    key: 'entropyCoef',
    label: 'Entropy coefficient',
    description: 'Encourage policy exploration',
    type: 'float',
    defaultValue: 0.01,
    min: 0,
    max: 0.05,
    step: 0.001,
  },
  {
    key: 'valueCoef',
    label: 'Value loss coefficient',
    description: 'Scale for critic loss term',
    type: 'float',
    defaultValue: 0.5,
    min: 0.1,
    max: 1,
    step: 0.05,
  },
  {
    key: 'rolloutHorizon',
    label: 'Rollout horizon',
    description: 'Steps per environment update',
    type: 'int',
    defaultValue: 2048,
    min: 256,
    max: 4096,
    step: 64,
  },
  {
    key: 'numEpochs',
    label: 'Update epochs',
    description: 'Gradient passes per batch',
    type: 'int',
    defaultValue: 10,
    min: 1,
    max: 30,
    step: 1,
  },
  {
    key: 'batchSize',
    label: 'Batch size',
    description: 'Size of rollout batch',
    type: 'int',
    defaultValue: 65536,
    min: 8192,
    max: 131072,
    step: 1024,
  },
  {
    key: 'miniBatchSize',
    label: 'Mini-batch size',
    description: 'Size of optimizer sub-batches',
    type: 'int',
    defaultValue: 2048,
    min: 256,
    max: 8192,
    step: 128,
  },
  {
    key: 'targetKl',
    label: 'Target KL',
    description: 'Early stop when exceeded',
    type: 'float',
    defaultValue: 0.015,
    min: 0.005,
    max: 0.05,
    step: 0.001,
  },
  {
    key: 'maxGradNorm',
    label: 'Max grad norm',
    description: 'Gradient clipping value',
    type: 'float',
    defaultValue: 0.5,
    min: 0.1,
    max: 2,
    step: 0.1,
  },
  {
    key: 'advantageNormalizer',
    label: 'Advantage normalization',
    description: 'Stabilize updates with norm',
    type: 'select',
    defaultValue: 'running',
    options: [
      { label: 'Running stats', value: 'running' },
      { label: 'Batch only', value: 'batch' },
      { label: 'Disabled', value: 'disabled' },
    ],
  },
];

const sacParameters: AlgorithmParameterDefinition[] = [
  {
    key: 'learningRate',
    label: 'Learning rate',
    description: 'Shared actor/critic lr',
    type: 'float',
    defaultValue: 0.0003,
    min: 0.00001,
    max: 0.01,
    step: 0.00001,
  },
  {
    key: 'gamma',
    label: 'Discount factor (gamma)',
    description: 'Reward discount',
    type: 'float',
    defaultValue: 0.99,
    min: 0.8,
    max: 0.999,
    step: 0.001,
  },
  {
    key: 'tau',
    label: 'Polyak tau',
    description: 'Target smoothing coefficient',
    type: 'float',
    defaultValue: 0.005,
    min: 0.001,
    max: 0.02,
    step: 0.001,
  },
  {
    key: 'targetEntropy',
    label: 'Target entropy',
    description: 'Auto temperature tuning',
    type: 'float',
    defaultValue: -3,
    min: -10,
    max: -1,
    step: 0.5,
  },
  {
    key: 'replaySize',
    label: 'Replay buffer size',
    description: 'Transitions stored',
    type: 'int',
    defaultValue: 1000000,
    min: 100000,
    max: 5000000,
    step: 50000,
  },
  {
    key: 'batchSize',
    label: 'Batch size',
    description: 'Training batch samples',
    type: 'int',
    defaultValue: 512,
    min: 64,
    max: 1024,
    step: 32,
  },
  {
    key: 'gradientSteps',
    label: 'Gradient steps',
    description: 'Updates per rollout step',
    type: 'int',
    defaultValue: 2,
    min: 1,
    max: 8,
    step: 1,
  },
  {
    key: 'policyDelay',
    label: 'Policy delay',
    description: 'Critic-only steps before actor update',
    type: 'int',
    defaultValue: 1,
    min: 1,
    max: 4,
    step: 1,
  },
  {
    key: 'autoEntropy',
    label: 'Entropy tuning',
    description: 'Alpha schedule',
    type: 'select',
    defaultValue: 'auto',
    options: [
      { label: 'Automatic', value: 'auto' },
      { label: 'Fixed temperature', value: 'fixed' },
    ],
  },
  {
    key: 'initTemp',
    label: 'Initial alpha temperature',
    description: 'Start value for entropy coef',
    type: 'float',
    defaultValue: 0.1,
    min: 0.01,
    max: 1,
    step: 0.01,
  },
  {
    key: 'obsNormalizer',
    label: 'Observation normalization',
    description: 'Stabilize training signals',
    type: 'select',
    defaultValue: 'layernorm',
    options: [
      { label: 'LayerNorm encoder', value: 'layernorm' },
      { label: 'Running stats', value: 'running' },
      { label: 'Disabled', value: 'disabled' },
    ],
  },
];

const td3Parameters: AlgorithmParameterDefinition[] = [
  {
    key: 'learningRate',
    label: 'Learning rate',
    description: 'Adam lr for actor/critic',
    type: 'float',
    defaultValue: 0.0005,
    min: 0.00005,
    max: 0.005,
    step: 0.00005,
  },
  {
    key: 'gamma',
    label: 'Discount factor',
    description: 'Reward weighting',
    type: 'float',
    defaultValue: 0.99,
    min: 0.8,
    max: 0.999,
    step: 0.001,
  },
  {
    key: 'tau',
    label: 'Polyak tau',
    description: 'Target blend factor',
    type: 'float',
    defaultValue: 0.005,
    min: 0.001,
    max: 0.02,
    step: 0.001,
  },
  {
    key: 'policyNoise',
    label: 'Policy smoothing noise',
    description: 'Std applied before target action',
    type: 'float',
    defaultValue: 0.2,
    min: 0.05,
    max: 0.5,
    step: 0.01,
  },
  {
    key: 'noiseClip',
    label: 'Noise clip range',
    description: 'Clamp target noise',
    type: 'float',
    defaultValue: 0.5,
    min: 0.1,
    max: 1,
    step: 0.05,
  },
  {
    key: 'policyDelay',
    label: 'Policy delay',
    description: 'Delays actor updates',
    type: 'int',
    defaultValue: 2,
    min: 1,
    max: 4,
    step: 1,
  },
  {
    key: 'batchSize',
    label: 'Batch size',
    description: 'Samples per update',
    type: 'int',
    defaultValue: 512,
    min: 64,
    max: 1024,
    step: 32,
  },
  {
    key: 'replaySize',
    label: 'Replay buffer size',
    description: 'Transitions stored',
    type: 'int',
    defaultValue: 2000000,
    min: 100000,
    max: 5000000,
    step: 50000,
  },
  {
    key: 'explorationNoise',
    label: 'Exploration noise',
    description: 'Std of action noise',
    type: 'float',
    defaultValue: 0.1,
    min: 0.01,
    max: 0.5,
    step: 0.01,
  },
  {
    key: 'warmupSteps',
    label: 'Warmup steps',
    description: 'Random policy duration',
    type: 'int',
    defaultValue: 10000,
    min: 1000,
    max: 20000,
    step: 500,
  },
];

const ddpgParameters: AlgorithmParameterDefinition[] = [
  {
    key: 'learningRateActor',
    label: 'Actor learning rate',
    description: 'Step size for policy net',
    type: 'float',
    defaultValue: 0.0004,
    min: 0.00005,
    max: 0.01,
    step: 0.00005,
  },
  {
    key: 'learningRateCritic',
    label: 'Critic learning rate',
    description: 'Step size for value net',
    type: 'float',
    defaultValue: 0.0008,
    min: 0.0001,
    max: 0.01,
    step: 0.00005,
  },
  {
    key: 'gamma',
    label: 'Discount factor',
    description: 'Reward discount',
    type: 'float',
    defaultValue: 0.98,
    min: 0.8,
    max: 0.999,
    step: 0.001,
  },
  {
    key: 'tau',
    label: 'Polyak tau',
    description: 'Target blend',
    type: 'float',
    defaultValue: 0.02,
    min: 0.001,
    max: 0.05,
    step: 0.001,
  },
  {
    key: 'batchSize',
    label: 'Batch size',
    description: 'Samples per update',
    type: 'int',
    defaultValue: 1024,
    min: 128,
    max: 2048,
    step: 64,
  },
  {
    key: 'replaySize',
    label: 'Replay buffer size',
    description: 'Transitions stored',
    type: 'int',
    defaultValue: 1500000,
    min: 100000,
    max: 5000000,
    step: 50000,
  },
  {
    key: 'explorationNoise',
    label: 'Exploration noise',
    description: 'Std of Ornstein-Uhlenbeck noise',
    type: 'float',
    defaultValue: 0.2,
    min: 0.01,
    max: 0.5,
    step: 0.01,
  },
  {
    key: 'noiseTheta',
    label: 'OU theta',
    description: 'Mean reversion strength',
    type: 'float',
    defaultValue: 0.15,
    min: 0.01,
    max: 0.3,
    step: 0.01,
  },
  {
    key: 'noiseSigma',
    label: 'OU sigma',
    description: 'Volatility scale',
    type: 'float',
    defaultValue: 0.3,
    min: 0.05,
    max: 0.6,
    step: 0.01,
  },
  {
    key: 'warmupSteps',
    label: 'Warmup steps',
    description: 'Replay fill before updates',
    type: 'int',
    defaultValue: 5000,
    min: 1000,
    max: 20000,
    step: 500,
  },
];

export const algorithmTemplates: Record<AlgorithmType, AlgorithmTemplate> = {
  PPO: {
    key: 'PPO',
    title: 'Proximal Policy Optimization',
    description: 'Trust-region policy gradient for smooth continuous control',
    actionSpace: 'continuous',
    parameters: ppoParameters,
  },
  SAC: {
    key: 'SAC',
    title: 'Soft Actor-Critic',
    description: 'Maximum entropy actor-critic for high-dimensional control',
    actionSpace: 'continuous',
    parameters: sacParameters,
  },
  TD3: {
    key: 'TD3',
    title: 'Twin Delayed DDPG',
    description: 'Deterministic policy with twin critics and smoothing',
    actionSpace: 'continuous',
    parameters: td3Parameters,
  },
  DDPG: {
    key: 'DDPG',
    title: 'Deep Deterministic Policy Gradient',
    description: 'Baseline deterministic actor-critic for continuous actions',
    actionSpace: 'continuous',
    parameters: ddpgParameters,
  },
};

const randomId = () => Math.random().toString(36).slice(2, 9);

export const initialAlgorithms: AlgorithmConfig[] = [
  {
    id: randomId(),
    name: 'PPO-LSTM',
    version: 'v3.2.1',
    status: 'Healthy',
    type: 'PPO',
    lastRun: '12 mins ago',
    throughput: '2.8k FPS',
    parameters: {
      learningRate: 0.00025,
      gamma: 0.99,
      gaeLambda: 0.94,
      clipRange: 0.2,
      entropyCoef: 0.005,
      valueCoef: 0.5,
      rolloutHorizon: 2048,
      numEpochs: 10,
      batchSize: 65536,
      miniBatchSize: 2048,
      targetKl: 0.01,
      maxGradNorm: 0.5,
      advantageNormalizer: 'running',
    },
  },
  {
    id: randomId(),
    name: 'SAC Hybrid',
    version: 'v2.9.0',
    status: 'Warning',
    type: 'SAC',
    lastRun: '1 hr ago',
    throughput: '1.2k FPS',
    parameters: {
      learningRate: 0.0002,
      gamma: 0.99,
      tau: 0.01,
      targetEntropy: -3.3,
      replaySize: 1500000,
      batchSize: 512,
      gradientSteps: 2,
      policyDelay: 1,
      autoEntropy: 'auto',
      initTemp: 0.2,
      obsNormalizer: 'layernorm',
    },
  },
  {
    id: randomId(),
    name: 'DreamerV3',
    version: 'v1.7.4',
    status: 'Healthy',
    type: 'DDPG',
    lastRun: '4 hrs ago',
    throughput: '980 FPS',
    parameters: {
      learningRateActor: 0.0003,
      learningRateCritic: 0.0008,
      gamma: 0.98,
      tau: 0.02,
      batchSize: 1024,
      replaySize: 1200000,
      explorationNoise: 0.2,
      noiseTheta: 0.15,
      noiseSigma: 0.25,
      warmupSteps: 6000,
    },
  },
  {
    id: randomId(),
    name: 'A2C Lightweight',
    version: 'v5.1.0',
    status: 'Deprecated',
    type: 'TD3',
    lastRun: 'Yesterday',
    throughput: '450 FPS',
    parameters: {
      learningRate: 0.0006,
      gamma: 0.98,
      tau: 0.005,
      policyNoise: 0.25,
      noiseClip: 0.6,
      policyDelay: 2,
      batchSize: 384,
      replaySize: 1000000,
      explorationNoise: 0.15,
      warmupSteps: 8000,
    },
  },
];
